```
if(m == 0 || n == 0)[[unlikely]] return;

if(m == 4 && n == 4 && !(k & 3)){

__m256d av = _mm256_set1_pd(alpha);
__m256d bv = _mm256_set1_pd(beta);

auto tmp1 = _mm256_setzero_pd();
auto tmp2 = _mm256_setzero_pd();
auto tmp3 = _mm256_setzero_pd();
auto tmp4 = _mm256_setzero_pd();

for(size_t l = 0; l < k; l += 4)
{
auto atmp1 = _mm256_castpd_si256(_mm256_loadu_pd(A + l));
auto atmp2 = _mm256_castpd_si256(_mm256_loadu_pd(A + l + k));
auto atmp3 = _mm256_castpd_si256(_mm256_loadu_pd(A + l + 2 * k));
auto atmp4 = _mm256_castpd_si256(_mm256_loadu_pd(A + l + 3 * k));

tmp1 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp1, 0x00), _mm256_loadu_pd(B + l * n), tmp1);
tmp1 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp1, 0x55), _mm256_loadu_pd(B + (l + 1) * n), tmp1);
tmp1 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp1, 0xaa), _mm256_loadu_pd(B + (l + 2) * n), tmp1);
tmp1 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp1, 0xff), _mm256_loadu_pd(B + (l + 3) * n), tmp1);

tmp2 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp2, 0x00), _mm256_loadu_pd(B + l * n), tmp2);
tmp2 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp2, 0x55), _mm256_loadu_pd(B + (l + 1) * n), tmp2);
tmp2 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp2, 0xaa), _mm256_loadu_pd(B + (l + 2) * n), tmp2);
tmp2 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp2, 0xff), _mm256_loadu_pd(B + (l + 3) * n), tmp2);

tmp3 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp3, 0x00), _mm256_loadu_pd(B + l * n), tmp3);
tmp3 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp3, 0x55), _mm256_loadu_pd(B + (l + 1) * n), tmp3);
tmp3 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp3, 0xaa), _mm256_loadu_pd(B + (l + 2) * n), tmp3);
tmp3 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp3, 0xff), _mm256_loadu_pd(B + (l + 3) * n), tmp3);

tmp4 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp4, 0x00), _mm256_loadu_pd(B + l * n), tmp4);
tmp4 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp4, 0x55), _mm256_loadu_pd(B + (l + 1) * n), tmp4);
tmp4 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp4, 0xaa), _mm256_loadu_pd(B + (l + 2) * n), tmp4);
tmp4 = _mm256_fmadd_pd(_mm256_permute4x64_pd(atmp4, 0xff), _mm256_loadu_pd(B + (l + 3) * n), tmp4);
}

_mm256_storeu_pd(C, _mm256_fmadd_pd(av, tmp1, _mm256_mul_pd(bv, _mm256_loadu_pd(C))));
_mm256_storeu_pd(C + 1 * n, _mm256_fmadd_pd(av, tmp2, _mm256_mul_pd(bv, _mm256_loadu_pd(C + 1 * n))));
_mm256_storeu_pd(C + 2 * n, _mm256_fmadd_pd(av, tmp3, _mm256_mul_pd(bv, _mm256_loadu_pd(C + 2 * n))));
_mm256_storeu_pd(C + 3 * n, _mm256_fmadd_pd(av, tmp4, _mm256_mul_pd(bv, _mm256_loadu_pd(C + 3 * n))));
```