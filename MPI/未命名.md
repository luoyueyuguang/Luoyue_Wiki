# MPI

- 一些网站
    
    [Tutorials · MPI Tutorial](https://mpitutorial.com/tutorials/)
    
    [https://github.com/mpitutorial/mpitutorial](https://github.com/mpitutorial/mpitutorial)
    
    [MPI: A Message-Passing Interface Standard (mpi-forum.org)](https://www.mpi-forum.org/docs/mpi-4.0/errata-40.pdf)
    
    [MPI Forum (mpi-forum.org)](https://www.mpi-forum.org/)
    
    【【MPI系列】第二节-MPI并行编程技术-点对点通信】 [https://www.bilibili.com/video/BV1vv4y1K7ZY/?share_source=copy_web&vd_source=a6101292198e45bd1d497775bc3199ef](https://www.bilibili.com/video/BV1vv4y1K7ZY/?share_source=copy_web&vd_source=a6101292198e45bd1d497775bc3199ef)
    
    [message-passing-interface | Microsoft Learn](https://learn.microsoft.com/pdf?url=https%3A%2F%2Flearn.microsoft.com%2Fzh-cn%2Fmessage-passing-interface%2Ftoc.json)
### 什么是MPI

MPI(Message Passing Interface,即消息传递接口)是消息传递库的标准。而非语言或接口。具体使用方法需要依赖于具体实现(mpich,openmpi等）。

### MPI的消息传递模型设计

comm(通信器):定义一组能够互相发消息的进程。

rank(秩):进程分配的序号，进程间显性地通过秩来进行通信。

tag(标签):一个进程可以通过指定另一个进程的秩以及一个独一无二的消息_标签_（_tag_）来发送消息给另一个进程。这种通信被称作_点对点_（point-to-point）通信。

点对点通信：一个线程发送消息给另一个线程。

集体性通信:进程跟所有其他进程通信。

### MPI如何跑多机

如果想要跑多机的话需要配置一个host文件(非/etc/hosts)。host文件包含想要运行的所有节点的名称，并确认所有这些节点能通过ssh通信,并配置ssh免密。使用nfs。

> host文件可按如下配置：前边是节点名，后边是处理器核数。

```cpp
>>> cat host_file
cetus1:2
cetus2:2
cetus3:2
cetus4:2
```

![11188e58793f447d56c84c6d2319190.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/68e242b0-241d-46d8-acb0-043ed00f7379/11188e58793f447d56c84c6d2319190.png)

### MPI通信模式（MPI Communication Modes）

> MPI有四种通信模式:standard，buffered,synchronous,ready。

> standard由MPI来决定是先将消息拷贝至一个缓冲区然后立即返回，还是等待将数据发出去后返回。大部分MPI预留了一定的缓冲区，当发送消息长度小于缓冲区大小时，会将消息拷贝到一个缓冲区然后立即返回，否则当部分或全部消息发送完成后才返回。标准模式是非局部的。

![fb81aca1a8b4d550634669c6579ef65.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/af2843e0-67f3-480f-9972-ccbc6bc0111d/fb81aca1a8b4d550634669c6579ef65.png)

> buffered由MPI将消息拷贝至一个用户提供的缓冲区然后立即返回，消息发送由MPI在后台进行。用户必须确保缓冲区足够。buffed是局部的。在send之前必须有缓存区。

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/82565ddf-b98f-48b2-b4b5-fc839176331b/Untitled.png)

> synchronous在标准模式的基础上要求确认接收方已经开始接收数据后函数调用才返回。synchronous是非局部的

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/9fcf7ac8-2bdd-48db-a599-d08405df1dfd/Untitled.png)

> ready发送时必须确保接收方已经处于就绪状态(正在等待接收该消息)，否则将产生一个错误。 因为假设接收方已经准备好接收，一些握手开销可以减少，可以提升一些性能。

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c95a9768-cc64-4bc6-a379-3800c611bf5e/Untitled.png)

### MPI命名规则

> 与特定形式的MPI对象相关联的例程函数应该是MPI_CLASS_ACTION_SUBSET,如果子集不存在，应该是MPI_CLASS_ACTION。

> 如果没有与特定类相关联，应该是MPI_Action_subset(c形式)或MPI_ACTION_SUBSET(Fortran形式)

> Create:创建一个新对象 Get:获取对象的信息 Set:设置对象的信息 Delete:删除信息 Is:询问对象是否具有某个属性

> IN:在函数运行期间，可能会使用输入值，但不会更新参数 OUT:更新参数但不会使用它的输入值 INOUT:使用输入值也会更新参数 如果参数是一个不透明的对象的句柄，并且对象被调用，这个 参数被标记为INOUT或OUT。

### MPI术语

- data buffer
    
    > message data buffer:用在通信程序中的send/receive buffer file data buffer:用在MPI I/O 程序中的buffer
    
- MPI operation
    
    包含四个阶段
    
    - Initialization:传入参数列表给操作，但没有数据缓冲区内容(如果有data buffe的话)。在释放操作之前，数组参数不能被更改。
    - Starting:将databuffer控制权交给相关操作。 一般用initiation指代Initialization和Starting
    - Cpmpletion:返回databuffer的控制权的内容并表明输出buffer和参数已经被更新。当这个阶段返回时，MPI操作已经完成。
    - Freeing:返回控制权给剩余的参数列表。

### MPI操作的形式

- 阻塞操作
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/424e27c1-9783-478f-a735-01dea3ae7d52/Untitled.png)
    
- 非阻塞操作
    
    > Initialization和starting是非阻塞的。Completion和freeing可以是非阻塞的，也可以是阻塞的。
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/650b28cf-26cb-4b12-b786-1a3303c0c821/Untitled.png)
    
- 持久操作
    
    四个阶段都被分开。可以是阻塞或非阻塞的。
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3a7ebc0d-2ceb-4f56-92b9-2ea48745bc53/Untitled.png)
    
- 集合操作
    
    一组或多组MPI进程的操作，在所有进程开始阶段启动前，有的进程已完成。
    
- 非集合操作
    
    不是集合操作的操作
    

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8b342428-8040-48fb-b77d-39c77b0324d3/Untitled.png)

### message envelope

```cpp
source
destination
tag
communicator
```

### MPI datatype

- MPI与 c语言对应的数据结构如下。
    
    ```cpp
    MPI_SHORT:short int
    MPI_INT:int
    MPI_LONG:long int
    MPI_LONG_LONG:long long int
    MPI_UNSIGNED_CHAR:unsigned char
    MPI_UNSIGNED_SHORT:unsigned short int
    MPI_UNSIGNED:unsigned int
    MPI_UNSIGNED_LONG:unsigned long int
    MPI_UNSIGNED_LONG_LONG:unsigned long long int
    MPI_FLOAT:float
    MPI_DOUBLE:double
    MPI_LONG_DOUBLE:long double
    MPI_BYTE:char
    ```
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/aa0c65b4-0545-4cd0-b897-e823b12b4975/Untitled.png)
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/03c80131-1d25-4800-8a66-4baece133735/Untitled.png)
    
    一些可用于MINLOC和MAXLOC的datatype
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e14ae271-2b63-4d21-8790-5ece5e437709/Untitled.png)
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/bc8e225c-1d26-4c41-99de-ddb3b7f49212/Untitled.png)
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6023acbe-51da-463e-9b08-4b201ab5ee78/Untitled.png)
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f84be115-0d68-4bc0-880e-cdb3d9d9c0c9/Untitled.png)
    
- predefined
    
    有预定义的名字的datatype.
    
- derived
    
    非predefined的datatype
    
- portable
    
    predefined的datatype是portable的。derived的datatype通过type constructors构建。
    
    ```cpp
    MPI_TYPE_CONTIGUOUS,
    MPI_TYPE_VECTOR, 
    MPI_TYPE_INDEXED,
    MPI_TYPE_CREATE_INDEXED_BLOCK, 
    MPI_TYPE_CREATE_SUBARRAY,
    MPI_TYPE_DUP, 
    MPI_TYPE_CREATE_DARRAY.
    ```
    
- equivalent
    
    如果两个Datatype看起来是通过相同的一系列调用和参数创建的，并且具有相同的类型映射，那么他们两个是等效的。
    

### MPI_Status结构体

> 在c语言中，status是一个结构体。MPI_SOURCE,MPI_TAG,MPI_ERROR对用户可见。

> MPI_SOURCE:源，发送端的rank。 MPI_TAG:消息的标签。 MPI_ERROR:消息的错误码

> 有些时候并不需要消息的详细信息时，可以用MPI_STATUS_IGNORE 或 MPI_STATUSES_IGNORE代替。(注意:status不能是IN)

```cpp
typedef struct _MPI_Status {
  int count;
  int cancelled;
  int MPI_SOURCE;
  int MPI_TAG;
  int MPI_ERROR;
} MPI_Status, *PMPI_Status;
```

### MPI_ANY_SOURCE和MPI_ANY_TAG

> source为MPI_ANY_SOURCE时表示任何进程发送的消息都可以接收。

> tag为MPI_ANY_TAG时，任何tag都是可接收。

### MPI_IN_PLACE

`MPI_IN_PLACE` 用在 `MPI_GATHER` 、`MPI_Reduce` 等有 `send_buf` 和 `recv_buf` 的函数中，用来代替 `send_buf`或`recv_buf`，说明**当前进程既发送又接受数据，而且要发送的数据和在要接收的数据的保存在同一内存。**

### MPI_Group

组是一个进程的有序集合。

### B, S, R, I

B

S

R

I

buffered mode

synchronous mode

ready mode

immediate or incomplete

### MPI基础函数

[MPI基础函数](https://www.notion.so/MPI-4274ccca10ba4664aa4f9c8dfce448e5?pvs=21)

### MPI中的send和recv(暨点对点通信常用函数)

[MPI中的send和recv(暨点对点通信常用函数)](https://www.notion.so/MPI-send-recv-e38e0c376d974c139b60e7c59500164e?pvs=21)

### MPI_File(暨MPI文件函数)

[MPI_File(暨MPI文件函数)](https://www.notion.so/MPI_File-MPI-8982d041881a42d8807b3fa932c913dc?pvs=21)

### MPI_Group(暨通信域与组的函数)

[MPI_Group(暨通信域与组的函数)](https://www.notion.so/MPI_Group-78a169fe9d9048efb4995bbf8524e86c?pvs=21)

### MPI的Gather与Scatter与Reduce(暨组与集群通信与归约函数)

[MPI的Gather与Scatter与Reduce(暨组与集群通信与归约函数)](https://www.notion.so/MPI-Gather-Scatter-Reduce-ada415fa308540d5ad899c4cc5197578?pvs=21)

### MPI常量

MPI_MAX_PROCESSOR_NAME MPI_MAX_LIBRARY_VERSION_STRING MPI_MAX_ERROR_STRING MPI_MAX_DATAREP_STRING MPI_MAX_INFO_KEY MPI_MAX_INFO_VAL MPI_MAX_OBJECT_NAME

MPI_MAX_PORT_NAME MPI_VERSION MPI_SUBVERSION MPI_F_STATUS_SIZE (C only) MPI_STATUS_SIZE (Fortran only) MPI_ADDRESS_KIND (Fortran only) MPI_COUNT_KIND (Fortran only) MPI_INTEGER_KIND (Fortran only) MPI_OFFSET_KIND (Fortran only) MPI_SUBARRAYS_SUPPORTED (Fortran only) MPI_ASYNC_PROTECTS_NONBLOCKING (Fortran only)

---

- `MPI_Get_processor_name(char* name,` `int* name_length)`
    
    > 这个函数会得到当前进程跑的时候所在的处理器的名字。
    
    ```cpp
    // Get the name of the processor
    char processor_name[MPI_MAX_PROCESSOR_NAME];
    int name_len;
    MPI_Get_processor_name(processor_name, &name_len);
    ```
    
- `MPI_Type_size()`
    
    > 返回数据类型所占的字节数
    
    ![37f3d69340040c66e6f7fc4a7a028a0.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/51cd1749-f91f-498f-b26b-3173c57925b8/37f3d69340040c66e6f7fc4a7a028a0.png)
    
    ![45a0b8f3824787a2ee4234179810063.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ac5c347b-8ae8-4703-acc8-38b74d77c256/45a0b8f3824787a2ee4234179810063.png)
    
    ```cpp
    int MPI_Type_size(MPI_Datatype datatype, 
    									int *size)
    int MPI_Type_size_c(MPI_Datatype datatype, 
    										MPI_Count *size)
    ```
    
    ```cpp
    int MPI_Type_size_x(MPI_Datatype datatype, 
    										MPI_Count *size)
    ```
    
- `MPI_Wtime()`
    
    > 返回以浮点数形式展示的从1970-01-01到现在为止的秒数,可以多次调用 `MPI_Wtime` 函数，并去差值,计算运行时间。
    
    ```cpp
    double MPI_Wtime(void)
    ```
    
- `MPI_Wtick()`
    
    > 以秒为单位返回MPI_Wtime的时间精度。
    
    ```cpp
    double MPI_Wtick(void)
    ```