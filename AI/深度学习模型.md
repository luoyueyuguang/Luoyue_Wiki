![[Pasted image 20250415235001.png]]
- **输入层** 接收原始数据并通过网络传递。
- **隐藏层** 评估和处理输入数据并将其转换为输出。
- **输出层** 使用处理后的数据来得出结果。
---
### **多层感知机（MLP, Multilayer Perceptron）**

多层感知机是最基础的神经网络模型，由输入层、隐藏层和输出层组成。每一层的神经元通过全连接的方式与下一层相连。尽管MLP结构简单，但它可以处理非线性问题，是许多复杂模型的基础。

---

## CNN(Convolutional Neural Network) 卷积神经网络
卷积是通过矩阵运算的方式将输入数据进行空间上的滤波，有效地提取数据中的局部特征，从而实现特征数据更高程度的抽象表示。
![[Pasted image 20250415235615.png]]
不适用于序列数据，无法处理时序信息。

---
### RNN(RecurrentNeuralNetwork)循环神经网络
RNN将上一次的输出混合下一次的输入再做一次计算，每次计算都对上一次的计算结果有一定的依赖。
![[Pasted image 20250415235828.png]]解决了输入数据是连续的序列问题

---
## LSTM（long short-term memory）（基于RNN的扩展）
![[Pasted image 20250416000116.png]]
LSTM 是RNN的一种变体，通过“门”结构引入“选择性遗忘”机制,解决梯度消失或梯度爆炸问题

---
### GAN（Generative Adversarial Networks）生成对抗网络
GAN由生成器和判别器组成。二者相互对抗，生成器网络负责生成数据并且欺骗判别器网络，而判别器网络负责识别哪些数据是真实的。
![[Pasted image 20250416000239.png]]

---

## Transformer
Transformer是一种基于注意力机制的模型，最初用于自然语言处理任务。它通过自注意力机制捕捉序列中不同位置之间的关系，避免了RNN的顺序计算瓶颈。
![[Pasted image 20250416000555.png]]

